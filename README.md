# Empathy-LLM-Dataset-Pipeline

Pipeline completo de procesamiento de datos para la generaci√≥n de un dataset de entrenamiento de modelos de lenguaje con capacidades de empat√≠a y detecci√≥n de riesgos en salud mental.

[![Python 3.11](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/downloads/release/python-3110/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![OpenAI API](https://img.shields.io/badge/OpenAI-API-green.svg)](https://openai.com/)

---

## üìã Descripci√≥n

Este repositorio contiene los **9 scripts** desarrollados como parte del Trabajo de Fin de M√°ster (TFM) en Inteligencia Artificial de la Universidad Internacional de Valencia (VIU). El proyecto implementa un pipeline completo para la generaci√≥n de un dataset de 20,132 ejemplos de di√°logos emp√°ticos en espa√±ol latinoamericano (variante peruana), dise√±ado para entrenar modelos de lenguaje peque√±os (Small Language Models) con capacidades de:

- **Empat√≠a y validaci√≥n emocional**
- **Detecci√≥n de riesgos de salud mental**
- **An√°lisis multimodal textual** (emojis, patrones de escritura, an√°lisis longitudinal)
- **T√©cnicas terap√©uticas** (TCC, ACT, Entrevista Motivacional)

---

## üéØ Objetivo del Proyecto

Desarrollar un asistente de IA conversacional 100% offline y privado para apoyo emocional en dispositivos m√≥viles, con un modelo de lenguaje de 1B de par√°metros optimizado mediante fine-tuning con DoRA (Weight-Decomposed Low-Rank Adaptation) y cuantizaci√≥n a 4 bits.

---

## üóÇÔ∏è Estructura del Repositorio

```
empathy-llm-dataset-pipeline/
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ 1_classify_alexander_street.py
‚îÇ   ‚îú‚îÄ‚îÄ 2_segment_academic_texts.py
‚îÇ   ‚îú‚îÄ‚îÄ 3_classify_chunks_by_theme.py
‚îÇ   ‚îú‚îÄ‚îÄ 3.5_download_daic_woz_transcripts.py
‚îÇ   ‚îú‚îÄ‚îÄ 4_process_daic_woz.py
‚îÇ   ‚îú‚îÄ‚îÄ 5_merge_knowledge_bases.py
‚îÇ   ‚îú‚îÄ‚îÄ 6_rag_dataset_generator.py
‚îÇ   ‚îú‚îÄ‚îÄ 7_generate_multimodal_examples.py
‚îÇ   ‚îî‚îÄ‚îÄ 8_smote_implementation.py
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ metodologia.md
‚îÇ   ‚îú‚îÄ‚îÄ apendice_b_scripts.pdf
‚îÇ   ‚îî‚îÄ‚îÄ pipeline_diagram.png
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ LICENSE
```

---

## üöÄ Pipeline de Procesamiento

El pipeline consta de **9 scripts** que procesan datos de dos fuentes principales:

### Fase I: Procesamiento de Fuentes de Datos

#### Rama A: Alexander Street (Base de Conocimiento Acad√©mico)

| Script | Prop√≥sito | Input | Output |
|--------|-----------|-------|--------|
| **Script 1** | Clasificar documentos en di√°logos vs. textos acad√©micos | 1,330 archivos `.txt` | 25 di√°logos + 1,305 textos |
| **Script 2** | Segmentar textos en chunks de ~500 palabras | 1,305 textos | ~26,000 chunks |
| **Script 3** | Clasificar chunks por tema cl√≠nico | ~26,000 chunks | Chunks etiquetados |

#### Rama B: DAIC-WOZ (Entrevistas Cl√≠nicas Reales)

| Script | Prop√≥sito | Input | Output |
|--------|-----------|-------|--------|
| **Script 3.5** | Descargar transcripciones desde servidor oficial | 140 IDs | 140 archivos CSV |
| **Script 4** | Traducir al espa√±ol peruano y formatear | 140 transcripciones | 140 di√°logos JSON |

### Fase II: Fusi√≥n y Generaci√≥n Sint√©tica

| Script | Prop√≥sito | Input | Output |
|--------|-----------|-------|--------|
| **Script 5** | Fusionar ambas fuentes en base de conocimiento | Chunks + di√°logos | `knowledge_base.json` |
| **Script 6** | Generar di√°logos sint√©ticos con RAG | Base de conocimiento | 15,000 di√°logos |
| **Script 7** | Generar ejemplos multimodales | Dataset de emojis | 1,000 ejemplos |

### Fase III: Balanceo

| Script | Prop√≥sito | Input | Output |
|--------|-----------|-------|--------|
| **Script 8** | Balancear clases con SMOTE | 16,000 ejemplos | **20,132 ejemplos** |

---

## üìä Dataset Final

### Composici√≥n

- **Alexander Street:** 26,000 chunks + 25 di√°logos
- **DAIC-WOZ:** 140 di√°logos traducidos
- **RAG:** 15,000 di√°logos sint√©ticos
- **Multimodal:** 1,000 ejemplos
- **SMOTE:** +4,132 ejemplos sint√©ticos

**Total:** **20,132 ejemplos** en formato JSONL

### Distribuci√≥n de Clases de Riesgo

| Clase | Ejemplos | Porcentaje |
|-------|----------|------------|
| `NO_CRISIS` | ~8,000 | 40% |
| `LOW_DISTRESS` | ~6,000 | 30% |
| `MODERATE` | ~4,000 | 20% |
| `HIGH_SUICIDE_RISK` | ~2,132 | 10% |

---

## üõ†Ô∏è Tecnolog√≠as Utilizadas

### Lenguajes y Frameworks

- **Python 3.11**
- **LangChain** (segmentaci√≥n de texto)
- **scikit-learn** (TF-IDF, vectorizaci√≥n)
- **NumPy** (operaciones vectoriales)
- **pandas** (procesamiento de datos)

### APIs y Modelos

- **OpenAI API** (gpt-4.1-mini)
- **Emoji Sentiment Ranking v1.0** (dataset externo)

### Datasets Fuente

- **Alexander Street Press** - Counseling and Psychotherapy Transcripts
- **DAIC-WOZ** - Distress Analysis Interview Corpus (USC)

---

## üì¶ Instalaci√≥n

### Requisitos Previos

- Python 3.11+
- Cuenta de OpenAI con API key
- Acceso a los datasets fuente (Alexander Street y DAIC-WOZ)

### Pasos de Instalaci√≥n

1. **Clonar el repositorio:**

```bash
git clone https://github.com/tu-usuario/empathy-llm-dataset-pipeline.git
cd empathy-llm-dataset-pipeline
```

2. **Crear entorno virtual:**

```bash
python3.11 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. **Instalar dependencias:**

```bash
pip install -r requirements.txt
```

4. **Configurar variables de entorno:**

```bash
cp .env.example .env
# Editar .env y a√±adir tu OPENAI_API_KEY
```

---

## üîß Uso

### Ejecuci√≥n Secuencial del Pipeline

Los scripts deben ejecutarse en orden:

```bash
# Fase I - Rama A: Alexander Street
python scripts/1_classify_alexander_street.py
python scripts/2_segment_academic_texts.py
python scripts/3_classify_chunks_by_theme.py

# Fase I - Rama B: DAIC-WOZ
python scripts/3.5_download_daic_woz_transcripts.py
python scripts/4_process_daic_woz.py

# Fase II: Fusi√≥n y Generaci√≥n
python scripts/5_merge_knowledge_bases.py
python scripts/6_rag_dataset_generator.py
python scripts/7_generate_multimodal_examples.py

# Fase III: Balanceo
python scripts/8_smote_implementation.py
```

### Configuraci√≥n de Rutas

Cada script tiene variables de configuraci√≥n al inicio del archivo. Ajusta las rutas seg√∫n tu entorno:

```python
# Ejemplo en 1_classify_alexander_street.py
INPUT_DIR = "/ruta/a/alexander_street_data"
OUTPUT_DIR = "/ruta/a/salida"
```

---

## ‚öôÔ∏è Par√°metros Clave

### Script 2: Segmentaci√≥n

```python
CHUNK_SIZE_WORDS = 500  # Tama√±o de chunk en palabras
OVERLAP_WORDS = 50      # Overlap entre chunks
```

### Script 3: Clasificaci√≥n Tem√°tica

```python
MODEL = "gpt-4.1-mini"
TEMPERATURE = 0.0  # Determinista para clasificaci√≥n
```

### Script 4: Traducci√≥n DAIC-WOZ

```python
MODEL = "gpt-4.1-mini"
TEMPERATURE = 0.3  # Baja para consistencia
```

### Script 6: Generaci√≥n RAG

```python
MODEL = "gpt-4.1-mini"
TEMPERATURE = 0.8  # Creatividad moderada
TOP_K_CHUNKS = 2   # Chunks recuperados por consulta
```

### Script 8: SMOTE

```python
K_NEIGHBORS = 5      # Vecinos para interpolaci√≥n
RANDOM_STATE = 42    # Reproducibilidad
```

---

## üí∞ Costos Estimados

### Costos de API (OpenAI)

| Script | Tiempo Estimado | Costo Estimado |
|--------|-----------------|----------------|
| Script 3 | 2-3 horas | $5-10 |
| Script 4 | 2-3 horas | $10-15 |
| Script 6 | 8-12 horas | $50-80 |
| Script 7 | 2-3 horas | $10-15 |
| **Total** | **16-22 horas** | **$75-120** |

*Nota: Los costos son aproximados y dependen del pricing de OpenAI en el momento de ejecuci√≥n.*

---

## üìÑ Formato del Dataset

### Estructura JSONL

Cada l√≠nea del archivo `.jsonl` es un objeto JSON:

```json
{
  "dialog_id": "rag-empathy-12345",
  "turns": [
    {"role": "user", "text": "Me siento muy ansioso por los ex√°menes..."},
    {"role": "assistant", "text": "Entiendo que te sientas as√≠..."}
  ],
  "labels": {
    "risk_class": "LOW_DISTRESS",
    "risk_signals": ["ansiedad_acad√©mica"],
    "category": "empathy_training",
    "source": "rag_generated"
  },
  "meta": {
    "language": "es-PE",
    "domain": ["academic"],
    "generation_method": "rag_tfidf_gpt4.1mini"
  }
}
```

### Clases de Riesgo

- `NO_CRISIS`: Sin se√±ales de riesgo
- `LOW_DISTRESS`: Malestar leve
- `MODERATE`: Malestar moderado
- `HIGH_SUICIDE_RISK`: Riesgo alto/ideaci√≥n suicida

---

## üî¨ Metodolog√≠a RAG

El sistema de Generaci√≥n Aumentada por Recuperaci√≥n (RAG) implementado en el Script 6 utiliza:

1. **Indexaci√≥n:** TF-IDF con 5,000 features y n-gramas (1,2)
2. **Recuperaci√≥n:** Similitud coseno para seleccionar top-k chunks
3. **Few-shot Prompting:** 1-2 di√°logos de ejemplo en el prompt
4. **Generaci√≥n:** gpt-4.1-mini con temperatura 0.8
5. **Validaci√≥n:** Parseo y verificaci√≥n de formato JSON

---

## üìö Documentaci√≥n Adicional

- **Metodolog√≠a completa:** Ver `docs/metodologia.md`
- **Ap√©ndice de scripts:** Ver `docs/apendice_b_scripts.pdf`
- **Diagrama del pipeline:** Ver `docs/pipeline_diagram.png`

---

## ü§ù Contribuciones

Este repositorio es parte de un Trabajo de Fin de M√°ster acad√©mico. Si deseas contribuir o tienes sugerencias:

1. Abre un **Issue** describiendo tu propuesta
2. Haz un **Fork** del repositorio
3. Crea una **Pull Request** con tus cambios

---

## üìñ Citaci√≥n

Si utilizas este c√≥digo o metodolog√≠a en tu investigaci√≥n, por favor cita:

```bibtex
@mastersthesis{Rojas2025empathy,
  title={Desarrollo de un Asistente de IA Conversacional con Capacidades de Empat√≠a y Detecci√≥n de Riesgos para Apoyo Emocional en Dispositivos M√≥viles},
  author={Paul Florencio Rojas Quispe},
  year={2025},
  school={Universidad Internacional de Valencia},
  type={Trabajo de Fin de M√°ster}
}
```

---

## ‚öñÔ∏è Licencia

Este proyecto est√° licenciado bajo la **MIT License**. Ver el archivo `LICENSE` para m√°s detalles.

---

## üôè Agradecimientos

- **Alexander Street Press** por proporcionar acceso al corpus de transcripciones de psicoterapia
- **USC Institute for Creative Technologies** por el dataset DAIC-WOZ
- **Emoji Sentiment Ranking** por el dataset de sentimientos de emojis
- **OpenAI** por la API de gpt-4.1-mini
- **Universidad Internacional de Valencia (VIU)** por el apoyo acad√©mico

---

## üìß Contacto

**Autor:** Paul Florencio Rojas Quispe  
**Email:** paulrojas0610@gmail.com  
**LinkedIn:** https://www.linkedin.com/in/paul-rojas-60bb35114/
**Universidad:** Universidad Internacional de Valencia (VIU)  
**Programa:** M√°ster en Inteligencia Artificial

---

## üîó Enlaces Relevantes

- [Alexander Street Press](https://alexanderstreet.com/)
- [DAIC-WOZ Dataset](https://dcapswoz.ict.usc.edu/)
- [Emoji Sentiment Ranking](https://kt.ijs.si/data/Emoji_sentiment_ranking/)
- [OpenAI API Documentation](https://platform.openai.com/docs/)
- [LangChain Documentation](https://python.langchain.com/)

---

## üìù Notas Importantes

### Privacidad y √âtica

- Este proyecto fue desarrollado con estricto apego a protocolos √©ticos de investigaci√≥n en salud mental
- Los datos de DAIC-WOZ fueron utilizados bajo los t√©rminos de uso del dataset
- El modelo resultante est√° dise√±ado para **apoyo emocional**, no para diagn√≥stico cl√≠nico
- Se recomienda supervisi√≥n profesional en implementaciones reales

### Limitaciones

- El dataset est√° en espa√±ol latinoamericano
- Los di√°logos sint√©ticos pueden contener sesgos del modelo generador
- La traducci√≥n de DAIC-WOZ puede haber perdido matices culturales
- El sistema no reemplaza la atenci√≥n psicol√≥gica profesional

---

**√öltima actualizaci√≥n:** Octubre 2025  
**Versi√≥n:** 1.0.0

